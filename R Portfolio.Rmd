---
title: "R Portfolio"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{css, echo=FALSE}
div.warning {
  padding: 1em;
  margin: 1em 0;
  padding-left: 100px;
  background-size: 70px;
  background-repeat: no-repeat;
  background-position: 15px center;
  min-height: 120px;
  color: #000000;
    background-color: #bed3ec;
    border: solid 5px #dfedff;
}
```

```{r load-data, include=FALSE, warning=FALSE}
library(dplyr)
library(MASS)
library(tidyverse)
library(DescTools)


# Keeps 'random' consistent
set.seed(123)

# Imports data from CSVs

# Home dev
#dat1 <- read.csv('C:\\Users\\louis\\OneDrive\\Documents\\Education\\NGED\\University Work\\Year 2\\Y2-R-Portfolio\\Data\\all_sm_data.csv')
#dat2 <- read.csv(INSERT-SM-VOLUME-PATH-HERE)

# Work dev
dat1 <- read.csv('C:\\Users\\Admin\\Documents\\NGED Work\\CDP Smart Meter Data\\Data\\all_sm_data.csv')
dat2 <- read.csv('C:\\Users\\Admin\\Documents\\NGED Work\\CDP Smart Meter Data\\Data\\sm-vols-jan24-dummy.csv')
dat3 <- read.csv('C:\\Users\\Admin\\Documents\\University Work\\Y2\\Satistics and Probability Models Assessments\\R Portfolio\\Y2-R-Portfolio\\Data\\LV_load_monitor_721030.csv')
dat4 <- read.csv("Data\\historic-fault-data.csv")
```

```{r standard-functions, echo=FALSE}
# These functions will help reduce repeated code

# Removes all outliers (> 1.5x IQR) from a given column
remove_outliers <- function(df, column) {
  Q1 <- quantile(column, 0.25)
  Q3 <- quantile(column, 0.75)
  IQR <- Q3 - Q1
  
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q1 + 1.5 * IQR
  
  filtered_df <- df[column >= lower_bound & column <= upper_bound,]
  
  return(filtered_df)
}
```
  
LO1: Can apply methods concerning estimation of parameters in standard statistical models; in particular the method of moments and the maximum likelihood method.

LO2: Can perform statistical hypotheses tests using data from studies (such as t and F-tests, comparison of models and parameter values).

LO3: Can apply methods for interval estimation; in particular, exact and approximate confidence intervals based on asymptotic theory.

LO4: Can apply methods for analysing categorical data.


## Evidence 1 - Distribution of customer energy consumption

Learning objective(s) assessed: **LO1 | LO3**

```{r 1.1-visualising-the-distribution}
# For each row, calculate the power consumed per device
dat1$import_per_device <- dat1$Total_consumption_active_import / dat1$aggregated_device_count_Active

# Filter the data set to remove erroneous data values
filt <- remove_outliers(dat1, dat1$import_per_device)

# Plot histogram of the values observed in power consumed per device
hist(filt$import_per_device, 
     breaks = seq(min(filt$import_per_device), max(filt$import_per_device), length.out = 30),
     main = "Distribution of average energy consumption per device per half hour",
     xlab = "Mean energy consumption (Wh)")
```

By dividing the total energy consumption by the number of active devices for each row we can find the the average (mean) energy consumption for each device for each half-hour interval. After removing outliers (greater than 1.5x the interquartile range) and plotting a histogram for the distribution of these values we can see a fairly normal graph.

To find good estimates for the mean and standard deviation of this distribution we can use the maximum likelihood method:

```{r 1.2-mle}
# Fit normal distribution to the filtered data (find the maximum likelihood estimators for mean and standard deviation)
fit_norm <- fitdistr(filt$import_per_device, densfun = "normal")
print(fit_norm)
```

The maximum likelihood estimators for the mean ($\hat{\mu}$) and the standard deviation ($\hat{\sigma}$) are shown above with the standard error shown below them. A 95% confidence interval can be calculated for each estimator to help quantify the uncertainty of the estimations for the population parameters derived from the sample:

```{r 1.3-confidence-intervals}
# Finds the 95% confidence intervals for the MLEs of both the mean and standard deviation
conf_intervals <- confint(fit_norm, level=0.95)
print(conf_intervals)
```

By inserting these estimates into a random normal distribution generator we can compare the estimated shape of the population with the shape we observe in the sample.

```{r 1.4-compare-with-random-normal}
# Plot a random normal distribution using the MLEs to compare against actual distribution
test_data <- rnorm(10000,mean=fit_norm$estimate['mean'],sd=fit_norm$estimate['sd'])
hist(test_data, breaks = 30,
     main = "Distribution of random normal (mean = 223.6, s.d. = 92.2)",
     xlab = "Generated X value")
```

  
## Evidence 2 - Smart meter uptake in different regions
  
Learning objective(s) assessed: **LO4**

We have some data relating to the counts of smart and non-smart meters in each of our licence areas:

```{r 2.1-contingency-table}
# Grabs the names of all 4 different licence areas
LAs = unique(dat2$Licence_Area)

# Loops through each row in the data set and finds the number of smart and non-smart meters for each region
tab_dat = c()
for (LA in LAs) {
  filtered <- dat2[dat2$Licence_Area == LA,]
  
  S1 = sum(filtered$SMETS1)
  S2 = sum(filtered$SMETS2)
  nonS = sum(filtered$NON_SMART)
  
  row_dat = c(S1, S2, nonS)
  
  tab_dat = append(tab_dat, row_dat)
}

# This data is then stored in a 3x4 matrix (contingency table)
tab <- matrix(tab_dat, nrow=3, ncol=length(LAs), dimnames=list(c("SMETS1","SMETS2","NON SMART"),LAs))

print(tab)
```

Using this table we can test for the independence of the variables 'Licence Area' and 'Meter Type'.

$H_0:$ The meter type is independent of the licence area in which it resides.

$vs.$

$H_1:$ The meter type depends on the licence area in which the meter resides.

Under $H_0$ for large $n$ (which is applicable here as n = 8,124,921), 

$-2\log(\Lambda)\sim \chi_{(J-1)(K-1)}^{2} \space approximately,$

$-2\log(\Lambda)=2\sum\limits_{j=1}^{J}\sum\limits_{k=1}^{K}y_{jk}\log\left(\frac{y_{jk}}{\hat{e}_{jk}}\right)$

$\hat{e}_{jk}=\frac{y_{j\bullet}y_{\bullet k}}{n}$

```{r 2.2-G-Test, echo=FALSE}
# Uses a G-Test (with no correction) to test the independence of the licence area and the type of meter used by customers
results <- GTest(tab,correct="none")

print(results)
```
The p-value for this test is <2.2e-16 which is much less than 0.01. This suggests there is overwhelming evidence to reject the null hypothesis ($H_0$) and we can say the variables are not independent. This suggests that different areas have different levels of uptake of smart meters compared to others. 

## Evidence 3 - Monitoring Low Voltage
  
Learning objective(s) assessed: **LO1 | LO2 | LO3**

```{r 3.1-visualising-the-distribution}
# Filter to only voltage values 
dat_lv <- dat3[dat3$Units == 'V',]

# Plot initial histogram
hist(dat_lv$Value, breaks=30, main="Distribution of low voltage readings",
     xlab="Voltage")
```

Plotting the distribution of the 10-minute low voltage readings we find a shape that looks
a lot like a gamma distribution.

Using the same maximum likelihood estimation method as before, we are able to find good estimates for the two parameters of a gamma distribution (shape and rate):

```{r 3.2-mle}
# Fit gamma distribution to the subset data
fit_gamma <- fitdistr(dat_lv$Value, densfun = "gamma")

# Gets number of rows in dataset
n_rows <- length(dat_lv$Value)

print(fit_gamma)
```
As our dataset has a large number of observations (`r n_rows`), we are able to approximate
the confidence intervals for the maximum likelihood estimators of both the shape and rate
using the formula:

$\hat\theta$ ~ $N(\theta,I(\theta)^{-1})$

The Fisher / Expected information ($I(\theta)$) of the shape parameter, $k$, is equal to
$\psi_{1}(k)$ (the trigamma function).

The Fisher information of the rate parameter, ($\lambda$), is equal to $\frac{k}{\lambda^2}$.

Using these formulas we can find a 95% confidence intervals for the MLEs we calculated earlier:

```{r 3.3-approximate-confidence-intervals}
# Calculates the Fisher information for shape using trigamma function
shape_trigam <- trigamma(fit_gamma$estimate['shape'])

shape_var <- 1/shape_trigam  # Gets reciprocal of the Fisher information

# Uses qnorm to find upper and lower confidence intervals
shape_lwrb <- qnorm(0.025, mean=fit_gamma$estimate['shape'], sd=sqrt(shape_var))
shape_uprb <- qnorm(0.975, mean=fit_gamma$estimate['shape'], sd=sqrt(shape_var))

# Calculates the Fisher information for rate using k/(lambda^2)
rate_fisher <- fit_gamma$estimate['shape'] / (fit_gamma$estimate['rate']^2)

rate_var <- 1/rate_fisher # Gets reciprocal of the Fisher information

# Uses qnorm to find upper and lower confidence intervals
rate_lwrb <- qnorm(0.025, mean=fit_gamma$estimate['rate'], sd=sqrt(rate_var))
rate_uprb <- qnorm(0.975, mean=fit_gamma$estimate['rate'], sd=sqrt(rate_var))

voltage_mean <- mean(dat_lv$Value)  # Average used in later method

# Puts data into data frame for better formatting once printed
ci_table <- data.frame(
  Confidence_Interval = c("2.5%", "97.5%"),
  Shape = c(shape_lwrb, shape_uprb),
  Rate = c(rate_lwrb, rate_uprb)
)

print(ci_table)
```

As this is an approximation, the confidence interval is not completely accurate but this
method is often times easier than calculating the exact confidence interval.

From our histogram, it seems our voltage mean is too high (at `r round(voltage_mean, 2)`V) for the expected 230V UK standard. By using a one sample t-test we can check if this difference is significant.

$H_0:$ The mean of the voltage readings is not significantly greater than the 230V UK standard.

$vs.$

$H_1:$ The mean of the voltage readings is significantly greater than the 230V UK standard.

```{r 3.4-t-test}
# Perform t-test to check true mean
t_result <- t.test(dat_lv$Value, mu=230, alternative="greater")
print(t_result)
```

As our p-value is very small we can reject the null hypothesis and conclude that the sample data suggests a mean voltage value greater than 230V. Although not ideal, LV can range from 216V to 253V so our readings are still within the range of safe operation.

It would also be useful to know if the voltage remains constant over time. Grouping the January and March readings separately, we can use some an F-test to check if the variance changes.

$H_0:$ The variance in the voltage readings is the same in January and March.

$vs.$

$H_1:$ The variance in the voltage readings is different in January and March.

```{r 3.5-f-test}
jan_dat <- dat_lv[dat_lv$Timestamp < "2023-02-01",] # Anything before Feb (Jan)
march_dat <- dat_lv[dat_lv$Timestamp > "2023-02-29",] # Anything after Feb (March)

# Perform F-test to check change in variance
f_result <- var.test(jan_dat$Value, march_dat$Value, alternative="two.sided")
print(f_result)
```

Similarly to the t-test, we observe a very low p-value suggesting we reject the null hypothesis in favour of the alternative. We can say that the variance between the January values differ significantly from the variance between the March values.

## Evidence 4 - Time until next fault
  
Learning objective(s) assessed: **LO1**

Another important area of the business is fault prediction. 

```{r 4.1-aggregation}
# Aggregate by fault
faults <- dat4 %>%
  group_by(incident_ref) %>%
  summarise(licence_area = first(licence_area), # Should all be the same anyway
            interruption_date = min(interruption_date), # Gets earliest interruption date (will be from stage 1)
            restoration_date = max(restoration_date), # Gets latest restoration date (will be from last stage)
            voltage = first(voltage), # Should all be the same anyway
            report_ci = max(report_ci)) # Gets the largest value (the max number of customers off simultaneously)
```

By using historic fault records, we can calculate the time intervals (in seconds) between faults occurring on our network. Here we could split the data into seperate parts for each licence area or GSP/BSP but to keep things simple we will use the whole network.

```{r 4.2-intervals}
# Convert datetime column to POSIXct
faults$interruption_date <- as.POSIXct(faults$interruption_date, format = "%d/%m/%Y %H:%M:%S")

# Order data by datetime column
faults <- faults[order(faults$interruption_date), ]

faults$fault_interval <- NA  # Initialize the new column with NA

for (i in 2:nrow(faults)) {
  # Calculate time difference in seconds between current row and previous row
  interval <- difftime(faults$interruption_date[i], faults$interruption_date[i - 1], units = "secs")
  
  # Assign the calculated interval to the corresponding row in the new column
  faults$fault_interval[i] <- as.numeric(interval)
}
```

```{r 4.3-histogram}
# Remove the initial row (where interval = NA)
faults <- na.omit(faults)

# Remove any outliers from the fault interval column
faults <- remove_outliers(faults, faults$fault_interval)

# Plot distribution of time until
hist(faults$fault_interval, breaks=20, main="Distribution of time until next fault", xlab="Seconds until next fault")
```

Plotting the distribution of intervals on a histogram we can see a clear exponential decay. With this knowledge, we can now try to fit our data to an exponential distribution to find an estimate for the rate ($\lambda$) parameter.

```{r 4.4-mle-exp}
# gets MLE for lambda (rate) parameter
fit_exp <- fitdistr(faults$fault_interval, densfun="exponential")

print(fit_exp)
```

Once we have our estimate we can check it against a randomly generated exponential distribution with the same rate.

```{r 4.5-compare-rand-exp}
# Generates a random exponential distribution with the MLE rate
test_dat <- rexp(10000, rate=fit_exp$estimate)

# Plots random distribution
hist(test_dat, xlim = c(0, 1000), breaks = 50, main = "Distribution of random Exponential (lambda = 0.002978)", xlab = "Generated X value")
```

The shape of the distribution is very similar which indicates the value found is a good estimation for $\lambda$. An alternative method for parameter estimation is the 'Method of Moments'. This method simply equates theoretical and sample moments - choosing to ensure the distribution ‘matches’ the data in the sense of equating the moments. For a single parameter this means solving:
$E(X) = \bar{X}$

The expected value of X where X ~ $Exp(\lambda)$ is defined as:
$E(X) = \frac{1}{\lambda}$

We can find $\bar{X}$ (sample mean) by summing the time intervals and then dividing the result by the number of intervals in our data set.

```{r 4.6-mom-exp, include=FALSE}
# Sum and count for mean calc
interval_sum <- format(sum(faults$fault_interval), scientific=TRUE)
count <- length(faults$fault_interval)

# Gets mean time interval between faults
sample_mean <- mean(faults$fault_interval)

# MoM for exponential
lambda_estimate <- 1/sample_mean
```

$\bar{X}$ = `r interval_sum` / `r count` = `r sample_mean`

Using the equations above we can say

`r sample_mean` = $\frac{1}{\lambda}$

$\therefore \space \hat\lambda$ = 1 / `r sample_mean` = `r lambda_estimate`

This estimate is coincidentally the same as the estimate derived using the maximum likelihood estimator methods above.
